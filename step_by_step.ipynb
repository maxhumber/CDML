{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature and energy demand data (MW) for the City of Toronto for the last 2 years... scraped by me!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/weather_power.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>energy_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>-16.9</td>\n",
       "      <td>5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>5211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>5096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>4987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>4926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  temperature  energy_demand\n",
       "0  2018-01-01 00:00:00        -16.9           5340\n",
       "1  2018-01-01 01:00:00        -16.3           5211\n",
       "2  2018-01-01 02:00:00        -17.6           5096\n",
       "3  2018-01-01 03:00:00        -18.6           4987\n",
       "4  2018-01-01 04:00:00        -17.8           4926"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select and split... we'll just use temperature for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = 'energy_demand'\n",
    "y = df[target]\n",
    "X = df[['temperature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Max's Tip: you should try to get to a number as quickly as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use [`DummyRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html) to make this happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "model = DummyRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DummyRegressor` will literally just predict the average for everything... doesn't matter what you put in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5692.04161844, 5692.04161844, 5692.04161844, ..., 5692.04161844,\n",
       "       5692.04161844, 5692.04161844])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can confirm by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5692.041618441358"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we have a model that we can score so that we know what to beat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1451.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "round(mean_squared_error(y_test, model.predict(X_test)) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the average is ~ 5700 MW our model right now is off by about 1400 MW on every prediction... not super great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a prediction for a single row, or new entry, I like to send things to a dictionary to get a sense of structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': [17.1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(1).to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to take that and embed it in a new pandas.DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5692.041618441358"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.DataFrame({'temperature': [21]})\n",
    "model.predict(new)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model so that we can wrap an app around the serialized version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5692.041618441358"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "model.predict(new)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to sit this model behind an app. For now, it's just going to be a shitty hello world: Flask app. Write this to a file called `app.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Hello'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the app by running it from the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 122-223-301\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrupt (ctrl+c, or Kernel > Interrupt) when finished to move on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some boilerplate in place, we can extend the hello world example to include the model. Though this looks like it'll work... it won't, but run it anyway:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import pickle\n",
    "\n",
    "from flask import Flask\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    new = pd.DataFrame({'temperature': [20]})\n",
    "    prediction = model.predict(new)\n",
    "    print(prediction)\n",
    "    return prediction\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the app at the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 122-223-301\n",
      "[5692.04161844]\n",
      "127.0.0.1 - - [21/Aug/2020 19:27:30] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2464, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2450, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1867, in handle_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1953, in full_dispatch_request\n",
      "    return self.finalize_request(rv)\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 1968, in finalize_request\n",
      "    response = self.make_response(rv)\n",
      "  File \"/Users/max/opt/miniconda3/lib/python3.8/site-packages/flask/app.py\", line 2127, in make_response\n",
      "    raise TypeError(\n",
      "TypeError: The view function did not return a valid response. The return type must be a string, dict, tuple, Response instance, or WSGI callable, but it was a ndarray.\n",
      "127.0.0.1 - - [21/Aug/2020 19:27:30] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:27:30] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=jquery.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:27:30] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:27:30] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=ubuntu.ttf HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:27:30] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you visit http://127.0.0.1:5000/ you'll get a:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TypeError** \n",
    "\n",
    "> TypeError: The view function did not return a valid response. The return type must be a string, dict, tuple, Response instance, or WSGI callable, but it was a ndarray.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrupt the kernel so that we can move on and fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the return type issue we can just return a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import pickle\n",
    "from flask import Flask\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    new = pd.DataFrame({'temperature': [20]})\n",
    "    prediction = model.predict(new)[0]\n",
    "    # return str(prediction)\n",
    "    return {'prediction': prediction}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you could `return str(prediction)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the app, to confirm that it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 122-223-301\n",
      "127.0.0.1 - - [21/Aug/2020 19:31:23] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:31:23] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:31:23] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:31:23] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:31:23] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=jquery.js HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:31:23] \"\u001b[37mGET /?__debugger__=yes&cmd=resource&f=ubuntu.ttf HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now our app is just returning the prediction for when the temperature is 20 degrees. In order to make it dynamic, we need to use \"query params\"... they look like:\n",
    "\n",
    "`http://website.com/endpoint?query=string`\n",
    "\n",
    "Query params will allow our model to accept different inputs. In order to capture query params, we need to import the `flask.request` object so that we can peel off `request.args` (basically just a dictionary).\n",
    "\n",
    "At the same time, we're going to add a temperature endpoint and re-organize the structue of the app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import pickle\n",
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Use the /predict endpoint'\n",
    "\n",
    "@app.route('/predict')\n",
    "def predict():\n",
    "    query = request.args\n",
    "    print(query)\n",
    "    new = pd.DataFrame({'temperature': [20]})\n",
    "    prediction = model.predict(new)[0]\n",
    "    return {'prediction': prediction}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and watch the command line when you enter arbitrary query strings like:\n",
    "    \n",
    "- http://127.0.0.1:5000/predict?hi=there&name=max\n",
    "- http://127.0.0.1:5000/predict?even=more&query=strings\n",
    "- http://127.0.0.1:5000/predict?temperature=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 122-223-301\n",
      "ImmutableMultiDict([('hi', 'there'), ('name', 'max')])\n",
      "127.0.0.1 - - [21/Aug/2020 19:35:22] \"\u001b[37mGET /predict?hi=there&name=max HTTP/1.1\u001b[0m\" 200 -\n",
      "ImmutableMultiDict([('even', 'more'), ('query', 'strings')])\n",
      "127.0.0.1 - - [21/Aug/2020 19:35:24] \"\u001b[37mGET /predict?even=more&query=strings HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2020 19:35:24] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will return `ImmutableMultiDict([('hi', 'there'), ('name', 'max')])` which is just a fancy dictionary..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 05 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To *actually* connect the temperature query string to the model, we'll grab it off `request.args` and format it as a float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import pickle\n",
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Use the /predict endpoint'\n",
    "\n",
    "@app.route('/predict')\n",
    "def predict():\n",
    "    query = request.args\n",
    "    temperature = float(query.get('temperature'))\n",
    "    print(temperature)\n",
    "    new = pd.DataFrame({'temperature': [temperature]})\n",
    "    prediction = model.predict(new)[0]\n",
    "    return {'prediction': prediction}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the app at the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"app\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with stat\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 122-223-301\n",
      "25.0\n",
      "127.0.0.1 - - [21/Aug/2020 19:36:35] \"\u001b[37mGET /predict?temperature=25 HTTP/1.1\u001b[0m\" 200 -\n",
      "50.0\n",
      "127.0.0.1 - - [21/Aug/2020 19:36:40] \"\u001b[37mGET /predict?temperature=50 HTTP/1.1\u001b[0m\" 200 -\n",
      "30.0\n",
      "127.0.0.1 - - [21/Aug/2020 19:36:40] \"\u001b[37mGET /predict?temperature=30 HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And hit the url with some temperatures:\n",
    "\n",
    "- http://127.0.0.1:5000/predict?temperature=25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the print statement in the console is registering the different values, but the model is just returning the same thing.\n",
    "\n",
    "Well that shouldn't surprise, because our model is dumb! Let's fix our dummy model now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a number to beat, let's see if we can beat it with `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cae5216284c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this will break because our data has some NaNs in the temperature column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23040 entries, 0 to 23039\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           23040 non-null  object \n",
      " 1   temperature    22873 non-null  float64\n",
      " 2   energy_demand  23040 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 540.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not to worry, this is easily fixed with `DataFrameMapper` from [sklearn-pandas](https://github.com/scikit-learn-contrib/sklearn-pandas) (my secret weapon).\n",
    "\n",
    "DataFrameMapper accepts a list of tuples, where each tuple identifies the column name and then the transformer that operates on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('temperature', SimpleImputer())\n",
    "], df_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works as though it's a first class transformer, so `fit`, `transform`, and `fit_transform` all work. Except it's a bit finnicky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "temperature: Expected 2D array, got 1D array instead:\narray=[-16.9 -16.3 -17.6 ...   9.1   8.7   8.3].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8172f748cb52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn_pandas/dataframe_mapper.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0my\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0mto\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn_pandas/dataframe_mapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, y, do_fit)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0madd_column_names_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdo_fit\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdo_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn_pandas/pipeline.py\u001b[0m in \u001b[0;36m_call_fit\u001b[0;34m(fit_method, X, y, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# fit takes only one argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_indicator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             X = self._validate_data(X, reset=in_fit,\n\u001b[0m\u001b[1;32m    242\u001b[0m                                     \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                                     \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: temperature: Expected 2D array, got 1D array instead:\narray=[-16.9 -16.3 -17.6 ...   9.1   8.7   8.3].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "mapper.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above hits a **Value Error**\n",
    "\n",
    "> ValueError: temperature: Expected 2D array, got 1D array instead:\n",
    "\n",
    "Because of how scikit-learn is desined. It has to do with the differences between how numbers and strings and columns are encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No worries, though, it's quickly fixed by wrapping the pesky column in square brackets (won't always work)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20731</th>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20732</th>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20733</th>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20734</th>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20735</th>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20736 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature\n",
       "0            -16.9\n",
       "1            -16.3\n",
       "2            -17.6\n",
       "3            -18.6\n",
       "4            -17.8\n",
       "...            ...\n",
       "20731         10.3\n",
       "20732          9.5\n",
       "20733          9.1\n",
       "20734          8.7\n",
       "20735          8.3\n",
       "\n",
       "[20736 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    (['temperature'], SimpleImputer())\n",
    "], df_out=True)\n",
    "\n",
    "mapper.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it works here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the DataFrameMapper, we can now transform our `X` objects to intermediate `Z` objects... \n",
    "\n",
    "> Max's Tip: You could just overwrite the `X`s but I like `Z`s becauxe they remind me \"HEY I DID SOMETHING TO THIS!~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_train = mapper.fit_transform(X_train)\n",
    "Z_test = mapper.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can score the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1345.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(mean_squared_error(y_test, model.predict(Z_test)) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find that this new model beats the dummy, albeit not by much. \n",
    "\n",
    "Let's peek at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21406</th>\n",
       "      <td>6000</td>\n",
       "      <td>5692.041618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21349</th>\n",
       "      <td>5942</td>\n",
       "      <td>5869.045155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22964</th>\n",
       "      <td>7224</td>\n",
       "      <td>5923.632752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20749</th>\n",
       "      <td>5489</td>\n",
       "      <td>5709.708384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22466</th>\n",
       "      <td>4777</td>\n",
       "      <td>5869.045155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22476</th>\n",
       "      <td>7557</td>\n",
       "      <td>5972.318988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21230</th>\n",
       "      <td>6526</td>\n",
       "      <td>5964.942285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21541</th>\n",
       "      <td>6082</td>\n",
       "      <td>5888.224581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22689</th>\n",
       "      <td>5623</td>\n",
       "      <td>5888.224581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22085</th>\n",
       "      <td>6005</td>\n",
       "      <td>5935.435476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20845</th>\n",
       "      <td>4789</td>\n",
       "      <td>5767.246662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22721</th>\n",
       "      <td>7024</td>\n",
       "      <td>5910.354688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>5488</td>\n",
       "      <td>5842.489026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22000</th>\n",
       "      <td>8181</td>\n",
       "      <td>6051.987373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613</th>\n",
       "      <td>7925</td>\n",
       "      <td>5976.745009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21974</th>\n",
       "      <td>7762</td>\n",
       "      <td>6009.202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21442</th>\n",
       "      <td>5648</td>\n",
       "      <td>5802.654833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20924</th>\n",
       "      <td>5196</td>\n",
       "      <td>5787.901429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21123</th>\n",
       "      <td>3956</td>\n",
       "      <td>5768.722003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21083</th>\n",
       "      <td>6965</td>\n",
       "      <td>5913.305369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22344</th>\n",
       "      <td>5656</td>\n",
       "      <td>5904.453326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22244</th>\n",
       "      <td>7448</td>\n",
       "      <td>5923.632752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21264</th>\n",
       "      <td>4958</td>\n",
       "      <td>5867.569814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20876</th>\n",
       "      <td>5178</td>\n",
       "      <td>5824.784941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22114</th>\n",
       "      <td>9198</td>\n",
       "      <td>5995.924435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_true        y_hat\n",
       "21406    6000  5692.041618\n",
       "21349    5942  5869.045155\n",
       "22964    7224  5923.632752\n",
       "20749    5489  5709.708384\n",
       "22466    4777  5869.045155\n",
       "22476    7557  5972.318988\n",
       "21230    6526  5964.942285\n",
       "21541    6082  5888.224581\n",
       "22689    5623  5888.224581\n",
       "22085    6005  5935.435476\n",
       "20845    4789  5767.246662\n",
       "22721    7024  5910.354688\n",
       "21513    5488  5842.489026\n",
       "22000    8181  6051.987373\n",
       "21613    7925  5976.745009\n",
       "21974    7762  6009.202500\n",
       "21442    5648  5802.654833\n",
       "20924    5196  5787.901429\n",
       "21123    3956  5768.722003\n",
       "21083    6965  5913.305369\n",
       "22344    5656  5904.453326\n",
       "22244    7448  5923.632752\n",
       "21264    4958  5867.569814\n",
       "20876    5178  5824.784941\n",
       "22114    9198  5995.924435"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_hat': model.predict(Z_test)\n",
    "}).sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have something a little more dynamic, we should \"serialize \" the mapper and the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapper.pkl', 'wb') as f:\n",
    "    pickle.dump(mapper, f)\n",
    "    \n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except this isn't super ideal because in this paradigm we have to keep track of and load two separate things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapper.pkl', 'rb') as f:\n",
    "    mapper = pickle.load(f)\n",
    "\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting a new sample is a matter of running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': [2.2]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.sample(1).to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5879.372538053129"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.DataFrame({'temperature': [21]})\n",
    "\n",
    "Z_new = mapper.transform(new)\n",
    "model.predict(Z_new)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But less is more, so I think we can do better..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter pipelines... a scikit-learn tool that will ensure that we only have to manage one thing.\n",
    "\n",
    "As an added bonus, using pipeline will make it so that we can get rid of the intermediate `Z` objects at the same time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(mapper, model)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now dump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load (to confirm it worked):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipe.pkl', 'rb') as f:\n",
    "    pipe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5879.372538053129"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(new)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deploying... we'll actually need our full model to be in a file, so let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "df = pd.read_csv('data/weather_power.csv')\n",
    "\n",
    "target = 'energy_demand'\n",
    "y = df[target]\n",
    "X = df[['temperature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (['temperature'], SimpleImputer())\n",
    "], df_out=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "pipe = make_pipeline(mapper, model)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "with open('pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy 01 - Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup a virtual environment:\n",
    "\n",
    "```\n",
    "python -m venv .venv\n",
    "```\n",
    "\n",
    "2. Activate it:\n",
    "\n",
    "```\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "3. Install app and model dependencies (`gunicorn` is for in between the web and flask):\n",
    "\n",
    "```\n",
    "pip install gunicorn flask scikit-learn pandas sklearn_pandas\n",
    "```\n",
    "\n",
    "3. Freeze the dependencies:\n",
    "\n",
    "```\n",
    "pip freeze > requirements.txt\n",
    "```\n",
    "\n",
    "4. Retrain the model inside of the virtual environment:\n",
    "\n",
    "```\n",
    "python model.py\n",
    "```\n",
    "\n",
    "5. Make sure the app still works locally:\n",
    "\n",
    "```\n",
    "python app.py\n",
    "```\n",
    "\n",
    "6. Specify a python runtime (3.8 not working yet):\n",
    "\n",
    "```\n",
    "python --version\n",
    "echo \"python-3.7.9\" > runtime.txt\n",
    "```\n",
    "\n",
    "7. Create a `Procfile`:\n",
    "\n",
    "```\n",
    "echo \"web: gunicorn app:app\" > Procfile\n",
    "```\n",
    "\n",
    "8. (Optional) If your project isn't already a git repo, make it one:\n",
    "\n",
    "```\n",
    "git init\n",
    "touch .gitignore\n",
    "echo \".venv\" >> .gitignore\n",
    "```\n",
    "\n",
    "9. Login to Heroku from the [command line](https://devcenter.heroku.com/articles/heroku-cli):\n",
    "\n",
    "```\n",
    "heroku login\n",
    "```\n",
    "\n",
    "10. Create a project:\n",
    "\n",
    "```\n",
    "heroku create\n",
    "```\n",
    "\n",
    "11. Add a remote to the randomly generated project:\n",
    "\n",
    "```\n",
    "heroku git:remote -a silly-words-009900\n",
    "```\n",
    "\n",
    "12. Test the app locally:\n",
    "\n",
    "```\n",
    "heroku local\n",
    "```\n",
    "\n",
    "13. add, commit push:\n",
    "\n",
    "```\n",
    "git add .\n",
    "git commit -m 'ðŸš€'\n",
    "git push heroku master\n",
    "```\n",
    "\n",
    "14. Hit the url and make sure it works!\n",
    "\n",
    "- http://\\<url\\>/predict?temperature=20\n",
    "\n",
    "15. Make sure nothing is wrong (check the logs!):\n",
    "\n",
    "```\n",
    "heroku logs -t \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAPI is the new kid on the block. It's faster, less boilerplate, and the future. Converting from Flask to FastAPI isn't that tough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "with open('pipe.pkl', 'rb') as f:\n",
    "    pipe = pickle.load(f)\n",
    "\n",
    "@app.get('/')\n",
    "def index():\n",
    "    return 'Use the /predict endpoint with a temperature argument'\n",
    "\n",
    "@app.get('/predict')\n",
    "def predict(temperature: float):\n",
    "    new = pd.DataFrame({'temperature': [temperature]})\n",
    "    prediction = pipe.predict(new)[0]\n",
    "    return {'prediction': prediction}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    uvicorn.run(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run at the command line with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn app:app --port 5000 --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it out and make sure it still works:\n",
    "\n",
    "- http://127.0.0.1:5000/predict?temperature=20\n",
    "\n",
    "As a bonus there's also some wicked auto-generate docs at:\n",
    "\n",
    "- http://127.0.0.1:5000/docs\n",
    "\n",
    "Interrupt and kill when you've verified it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heroku + fastAPI\n",
    "\n",
    "0. If you're not in your environment anymore you can re-enter with:\n",
    "\n",
    "`source .venv/bin/activate`\n",
    "\n",
    "(And to exit out to your base environment):\n",
    "\n",
    "`deactivate`\n",
    "\n",
    "1. Install the new dependencies:\n",
    "\n",
    "```\n",
    "pip install uvicorn fastapi\n",
    "```\n",
    "\n",
    "2. Freeze the dependencies:\n",
    "\n",
    "```\n",
    "pip freeze > requirements.txt\n",
    "```\n",
    "\n",
    "3. Retrain the model inside of the virtual environment:\n",
    "\n",
    "```\n",
    "python model.py\n",
    "```\n",
    "\n",
    "4. Make sure the app still works locally:\n",
    "\n",
    "```\n",
    "uvicorn app:app --port=5000\n",
    "```\n",
    "\n",
    "5. Create a new `Procfile`:\n",
    "\n",
    "```\n",
    "echo \"web: uvicorn app:app --host=0.0.0.0 --port=${PORT:-5000}\" > Procfile\n",
    "```\n",
    "\n",
    "6. Test the app locally:\n",
    "\n",
    "```\n",
    "heroku local\n",
    "```\n",
    "\n",
    "7. add, commit push:\n",
    "\n",
    "```\n",
    "git add .\n",
    "git commit -m 'ðŸš€'\n",
    "git push heroku master\n",
    "```\n",
    "\n",
    "8. Click on the url and make sure it works!\n",
    "\n",
    "- http://\\<url\\>/predict?temperature=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we have right now sucks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(range(len(y_test)), y_test)\n",
    "plt.plot(range(len(y_test)), model.predict(Z_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It barely explains anything... but it actually turns temperature can explain a lot when we properly handle the column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['temperature'], df['energy_demand'], alpha=1/20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we see a \"U\" or a rainbow, we should look at brining in Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (['temperature'], [SimpleImputer(), PolynomialFeatures(degree=2, include_bias=False)])\n",
    "], df_out=True)\n",
    "\n",
    "mapper.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a full pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(mapper, model)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(mean_squared_error(y_test, pipe.predict(X_test)) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explained over half of the variance and have our model off by < 1000 mw. Look at the updated prediction curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still have a lot of work to do, but let's wrap it up in a `model.py` file so that we can redeploy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "df = pd.read_csv('data/weather_power.csv')\n",
    "\n",
    "target = 'energy_demand'\n",
    "y = df[target]\n",
    "X = df[['temperature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    (['temperature'], [SimpleImputer(), PolynomialFeatures(degree=2, include_bias=False)])\n",
    "], df_out=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "pipe = make_pipeline(mapper, model)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "with open('pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dependencies have changed, so it's a lot easier to push a change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Retrain the model inside of the virtual environment:\n",
    "\n",
    "```\n",
    "python model.py\n",
    "```\n",
    "\n",
    "2. Test the app locally:\n",
    "\n",
    "```\n",
    "heroku local\n",
    "```\n",
    "\n",
    "3. add, commit push:\n",
    "\n",
    "```\n",
    "git add .\n",
    "git commit -m 'ðŸš€'\n",
    "git push heroku master\n",
    "```\n",
    "\n",
    "4. Click on the url and make sure it works!\n",
    "\n",
    "- http://\\<url\\>/predict?temperature=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 08 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now our model is just using temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(y_test)), y_test)\n",
    "plt.plot(range(len(y_test)), pipe.predict(Z_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has to be so relationship betwen date. And hour. Let's convert the date column from a string to a date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could import the data with the date column (0th position), already parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/weather_power.csv', parse_dates=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably want month, weekday and hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df['date']\n",
    "\n",
    "pd.concat([col.dt.month, col.dt.weekday, col.dt.hour], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recut the X and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'energy_demand'\n",
    "y = df[target]\n",
    "X = df[['date', 'temperature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a scikit-learn transformer to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DateEncoder(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return pd.concat([X.dt.month, X.dt.weekday, X.dt.hour], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That way we can apply it on the `X_train` and `X_test` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DateEncoder().fit_transform(X_train['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can easily embed it in our mapper framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    ('date', DateEncoder(), {'input_df': True}),\n",
    "    (['temperature'], [SimpleImputer(), PolynomialFeatures(degree=2, include_bias=False)])\n",
    "], df_out=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "pipe = make_pipeline(mapper, model)\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explains even more variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And shaving off more from RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, pipe.predict(X_test)) ** (1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(y_test)), y_test)\n",
    "plt.plot(range(len(y_test)), pipe.predict(X_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the way pickle works, we have move the `DateEncoder` to a `utils.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DateEncoder(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return pd.concat([X.dt.month, X.dt.weekday, X.dt.hour], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the complete model to a new file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from utils import DateEncoder # CUSTOM IMPORT\n",
    "\n",
    "df = pd.read_csv('data/weather_power.csv', parse_dates=[0])\n",
    "\n",
    "target = 'energy_demand'\n",
    "y = df[target]\n",
    "X = df[['date', 'temperature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('date', DateEncoder(), {'input_df': True}),\n",
    "    (['temperature'], [SimpleImputer(), PolynomialFeatures(degree=2, include_bias=False)])\n",
    "], df_out=True)\n",
    "\n",
    "model = LinearRegression()\n",
    "pipe = make_pipeline(mapper, model)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "with open('pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the custom `DateEncoder` and accept a dictionary in the index, and change it to a post request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from typing import Dict\n",
    "import os\n",
    "from utils import DateEncoder\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "with open('pipe.pkl', 'rb') as f:\n",
    "    pipe = pickle.load(f)\n",
    "\n",
    "@app.post('/')\n",
    "def index(json_data: Dict):\n",
    "    new = pd.DataFrame({\n",
    "        'date': [pd.Timestamp(json_data.get('date'))],\n",
    "        'temperature': [float(json_data.get('temperature'))]\n",
    "    })\n",
    "    prediction = pipe.predict(new)[0]\n",
    "    return {'prediction': prediction}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    uvicorn.run(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Carrier Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a post carrier to hit the local endpoint and when it's deployed, this is the function we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "\n",
    "def post(url, data):\n",
    "    data = bytes(json.dumps(data).encode(\"utf-8\"))\n",
    "    request = Request(\n",
    "        url=url,\n",
    "        data=data,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-type\", \"application/json; charset=UTF-8\")\n",
    "    with urlopen(request) as response:\n",
    "        data = json.loads(response.read().decode(\"utf-8\"))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy on Dokku (Heroku Open Source, and better)\n",
    "\n",
    "Create a new Procfile (respect port 5000):\n",
    "\n",
    "`echo \"web: uvicorn app:app --host=0.0.0.0 --port=${PORT:-5000}\" > Procfile`\n",
    "\n",
    "\n",
    "Rerun the model:\n",
    "\n",
    "```\n",
    "python model.py\n",
    "```\n",
    "\n",
    "Make sure the app works locally:\n",
    "\n",
    "```\n",
    "uvicorn app:app --port 5000 --reload\n",
    "```\n",
    "\n",
    "Use the post function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"date\": str(pd.Timestamp('now')),\n",
    "    \"temperature\": 25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post(\"http://127.0.0.1:5000\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've confirmed that it still works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy Dokku by:\n",
    "\n",
    "1. Sign up for a [DigitalOcean](https://m.do.co/c/2909cd1f3f10) account\n",
    "\n",
    "2. Spin up a $5 Ubuntu 20/18.04 server...\n",
    "\n",
    "3. ssh into it:\n",
    "\n",
    "```\n",
    "ssh root@165.XXX.43.118\n",
    "```\n",
    "\n",
    "4. (Strongly advised) Update everything:\n",
    "\n",
    "```\n",
    "sudo apt update\n",
    "sudo apt -y upgrade\n",
    "```\n",
    "\n",
    "5. Setup firewall:\n",
    "\n",
    "````\n",
    "ufw app list\n",
    "ufw allow OpenSSH\n",
    "ufw enable\n",
    "````\n",
    "\n",
    "6. Add some rules ([source](https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-with-ufw-on-ubuntu-18-04)):\n",
    "\n",
    "```\n",
    "sudo ufw default deny incoming\n",
    "sudo ufw default allow outgoing\n",
    "sudo ufw allow ssh\n",
    "sudo ufw allow 22\n",
    "sudo ufw allow http\n",
    "sudo ufw allow https\n",
    "```\n",
    "\n",
    "7. Install dokku:\n",
    "\n",
    "```\n",
    "wget https://raw.githubusercontent.com/dokku/dokku/v0.21.4/bootstrap.sh\n",
    "sudo DOKKU_TAG=v0.21.4 bash bootstrap.sh\n",
    "```\n",
    "\n",
    "**THIS STEP IS IMPORTANT!**\n",
    "\n",
    "8. Visit the Dropletâ€™s IP address in a browser to finish configuring Dokku\n",
    "\n",
    "\n",
    "9. Copy and paste your ssh key from your **laptop** into the config window:\n",
    "\n",
    "```\n",
    "cat .ssh/id_rsa.pub\n",
    "```\n",
    "\n",
    "10. And add the IP of the server to the hostname:\n",
    "\n",
    "`68.183.XXX.31`\n",
    "\n",
    "\n",
    "11. Click \"Finish Setup\"...\n",
    "\n",
    "\n",
    "12. Go back to the server terminal and create a dokku app on the server:\n",
    "\n",
    "```\n",
    "dokku apps:create powerapp\n",
    "dokku domains:enable powerapp\n",
    "\n",
    "```\n",
    "\n",
    "**On Laptop**\n",
    "\n",
    "12. Add dokku as a remote:\n",
    "\n",
    "```\n",
    "git remote add dokku dokku@165.XXX.43.118:powerapp\n",
    "```\n",
    "\n",
    "13. Verify that the remote got added:\n",
    "\n",
    "```\n",
    "git remote -v\n",
    "```\n",
    "\n",
    "14. Push it up (for every new change just run these commands):\n",
    "\n",
    "```\n",
    "git add .\n",
    "git commit -m 'ðŸ¤ž'\n",
    "git push dokku master\n",
    "```\n",
    "\n",
    "15. Test if it works with the post function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post(\"http://142.93.148.110\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('date', DateEncoder(), {'input_df': True}),\n",
    "    (['temperature'], [SimpleImputer(), PolynomialFeatures(degree=2, include_bias=False)])\n",
    "], df_out=True)\n",
    "\n",
    "Z_train = mapper.fit_transform(X_train)\n",
    "Z_test = mapper.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(Z_train.shape[1],)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    Z_train, y_train,\n",
    "    epochs=100, batch_size=32,\n",
    "    validation_data=(Z_test, y_test)\n",
    ")\n",
    "\n",
    "model.evaluate(Z_test, y_test)\n",
    "r2_score(y_test, model.predict(Z_test)), r2_score(y_test, model.predict(Z_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict something new:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame({\n",
    "    'date': [pd.Timestamp('now')],\n",
    "    'temperature': [17]\n",
    "})\n",
    "\n",
    "model.predict(mapper.transform(new))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(X_test['date'], y_test, alpha=1/2);\n",
    "plt.plot(X_test['date'], model.predict(Z_test).flatten(), alpha=1/2);\n",
    "\n",
    "round(mean_squared_error(y_test, model.predict(Z_test)) ** (1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a KerasRegressor Wrapper and a SelectKBest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "Z_train = mapper.fit_transform(X_train)\n",
    "Z_test = mapper.transform(X_test)\n",
    "\n",
    "columns = 5\n",
    "select = SelectKBest(k=columns)\n",
    "\n",
    "select.fit_transform(Z_train, y_train)\n",
    "\n",
    "def nn():\n",
    "    columns = 5\n",
    "    m = Sequential()\n",
    "    m.add(Input(shape=(columns,)))\n",
    "    m.add(Dense(10, activation='relu'))\n",
    "    m.add(Dense(10, activation='relu'))\n",
    "    m.add(Dense(1))\n",
    "    m.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='adam',\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    return m\n",
    "\n",
    "model = KerasRegressor(nn, epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the pipe can work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(mapper, select, model)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "new = pd.DataFrame({\n",
    "    'date': [pd.Timestamp('now')],\n",
    "    'temperature': [17]\n",
    "})\n",
    "\n",
    "float(pipe.predict(new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serializing is going to be a bit of a headache, need to dump the model first then pickle the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps['kerasregressor'].model.save('model.h5')\n",
    "pipe.named_steps['kerasregressor'].model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading it back in looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipe.pkl', 'rb') as f:\n",
    "    pipe = pickle.load(f)\n",
    "\n",
    "pipe.named_steps['kerasregressor'].model = load_model('model.h5')\n",
    "\n",
    "float(pipe.predict(new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should move the `nn` definition to utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "class DateEncoder(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return pd.concat([X.dt.month, X.dt.weekday, X.dt.hour], axis=1)\n",
    "    \n",
    "def nn():\n",
    "    columns = 5\n",
    "    m = Sequential()\n",
    "    m.add(Input(shape=(columns,)))\n",
    "    m.add(Dense(10, activation='relu'))\n",
    "    m.add(Dense(10, activation='relu'))\n",
    "    m.add(Dense(1))\n",
    "    m.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer='adam',\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the full model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from utils import DateEncoder, nn\n",
    "\n",
    "df = pd.read_csv('data/weather_power.csv', parse_dates=[0])\n",
    "\n",
    "target = 'energy_demand'\n",
    "y = df[target]\n",
    "X = df[['date', 'temperature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('date', DateEncoder(), {'input_df': True}),\n",
    "    (['temperature'], [SimpleImputer(), PolynomialFeatures(degree=2, include_bias=False)])\n",
    "], df_out=True)\n",
    "\n",
    "columns = 5\n",
    "select = SelectKBest(k=columns)\n",
    "\n",
    "model = KerasRegressor(nn, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "pipe = make_pipeline(mapper, select, model)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.named_steps['kerasregressor'].model.save('model.h5')\n",
    "pipe.named_steps['kerasregressor'].model = None\n",
    "\n",
    "with open('pipe.pkl', 'wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the tensorflow model and async and RequestData:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "from typing import Dict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from utils import DateEncoder, nn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "with open('pipe.pkl', 'rb') as f:\n",
    "    pipe = pickle.load(f)\n",
    "\n",
    "pipe.named_steps['kerasregressor'].model = load_model('model.h5')\n",
    "\n",
    "class RequestData(BaseModel):\n",
    "    date: str\n",
    "    temperature: float\n",
    "\n",
    "@app.post('/')\n",
    "async def index(request: RequestData): # add async and RequestData\n",
    "    new = pd.DataFrame({\n",
    "        'date': [pd.Timestamp(request.date)],\n",
    "        'temperature': [request.temperature]\n",
    "    })\n",
    "    prediction = float(pipe.predict(new))\n",
    "    return {'prediction': prediction}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    uvicorn.run(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Update environment:\n",
    "\n",
    "```\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "2. Freeze the dependencies:\n",
    "\n",
    "```\n",
    "pip freeze > requirements.txt\n",
    "```\n",
    "\n",
    "3. Retrain the model inside of the virtual environment:\n",
    "\n",
    "```\n",
    "python model.py\n",
    "```\n",
    "\n",
    "4. Make sure the app still works locally:\n",
    "\n",
    "```\n",
    "uvicorn app:app --port 5000 --reload\n",
    "```\n",
    "\n",
    "5. Push everything up to GitHub:\n",
    "\n",
    "```\n",
    "git add .\n",
    "git commit -m 'ðŸš€'\n",
    "git push dokku\n",
    "```\n",
    "\n",
    "6. Check logs on server (to make sure it all works)\n",
    "\n",
    "```\n",
    "dokku logs powerapp --tail\n",
    "```\n",
    "\n",
    "7. Test with the post function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"date\": str(pd.Timestamp('now')),\n",
    "    \"temperature\": 20\n",
    "}\n",
    "\n",
    "post(\"http://142.93.148.110\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it!\n",
    "\n",
    "New changes that don't have any new depends will just need:\n",
    "\n",
    "```\n",
    "git add .\n",
    "git commit -m 'ðŸš€'\n",
    "git push dokku\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
